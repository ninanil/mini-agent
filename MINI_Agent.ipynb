{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Things We Should Address\n",
        "\n",
        "1. **Tool Selection**  \n",
        "   We will initially implement tools as standalone functions. Later, we will refactor them into an object-oriented structure for better modularity and maintainability.\n",
        "\n",
        "2. **Prompt Design**  \n",
        "   Once the workflow is functional, we will apply prompt engineering techniques—such as few-shot learning—to improve the LLM's understanding of the MINI project.\n",
        "\n",
        "3. **Agent Structure**  \n",
        "   - **Built-in React Agent vs. Custom Agent**  \n",
        "     For now, we will use `create_react_agent` from LangChain to evaluate its benefits for our project.  \n",
        "     - One limitation of `create_react_agent` is that the prompt template is somewhat fixed, which may reduce flexibility.  \n",
        "     - For the `agent_scratchpad`, which is injected into the prompt, we don’t need to send the entire message history—just the last assistant response is sufficient.\n",
        "\n",
        "4. **React Agent Loop**  \n",
        "   - How the patient agent interacts with the React agent loop.\n",
        "\n",
        "5. **Agoraphobia JSON Fix**  \n",
        "   - The Agoraphobia module’s JSON file has been corrected and updated.\n"
      ],
      "metadata": {
        "id": "62m3jir4Ts1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install langchain-openai\n",
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "!pip install python-dotenv\n"
      ],
      "metadata": {
        "id": "Dy3eXXlOanPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any, Tuple\n",
        "\n",
        "def load_mini_module(file_path: str) -> Tuple[str, List[str], List[Dict[str, Any]], Dict[str, Dict[str, str]]]:\n",
        "    \"\"\"\n",
        "    Load MINI diagnostic module from JSON file.\n",
        "\n",
        "    Returns:\n",
        "        - module_id: e.g., 'E'\n",
        "        - instructions: list of string instructions\n",
        "        - questions: list of question dicts\n",
        "        - diagnostic_criteria: dict mapping condition to evaluation logic\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    module_id = data[\"module\"][\"id\"]\n",
        "    instructions = data.get(\"instructions\", [])\n",
        "    questions = data.get(\"questions\", [])\n",
        "    diagnostic_criteria = data.get(\"diagnosticCriteria\", {})\n",
        "\n",
        "    return module_id, instructions, questions, diagnostic_criteria\n",
        "\n",
        "# Example usage:\n",
        "# module_id, instructions, questions, criteria = load_mini_module(\"mini-modules/module_e.json\")\n",
        "# print(instructions)\n",
        "# print(questions[0]['prompt'])\n"
      ],
      "metadata": {
        "id": "7ge8GaGzWGey"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import tool\n",
        "@tool\n",
        "def ask_patient(question: str) -> str:\n",
        "    \"\"\"Ask the patient the current MINI question.\"\"\"\n",
        "    pass\n",
        "\n",
        "@tool\n",
        "def classify_answer(response: str) -> str:\n",
        "    \"\"\"Classify patient's natural-language response as 'yes', 'no', or 'unclear'.\"\"\"\n",
        "    pass\n",
        "@tool\n",
        "def explain(current_question: str) -> str:\n",
        "    \"\"\"Clarify or rephrase the current question to help the patient understand.\"\"\"\n",
        "    pass\n",
        "@tool\n",
        "def end_module() -> str:\n",
        "    \"\"\"Signal that the module has ended either due to logic or patient response.\"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "QaqoAVfFcf0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import tool\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "interview_prompt_template = \"\"\"\n",
        "You are an intelligent and empathetic interviewer conducting a psychiatric diagnostic session using the MINI system.\n",
        "\n",
        "You operate in a deliberate loop with the following structure:\n",
        "\n",
        "- **Thought**: Reflect on the current question, the patient's response (if available), and your reasoning about what to do next.\n",
        "- **Action**: Choose a tool to use from the available actions, then return \"PAUSE\".\n",
        "- **Observation**: Record the result returned by the tool (e.g., the patient's response, a classification, or a confirmation).\n",
        "- Repeat this loop as needed to continue the interview process.\n",
        "\n",
        "At the end of the loop, output an **Answer** — this should reflect one of the following:\n",
        "- The decision about what to do next (e.g., ask the next question),\n",
        "- A clarification or rephrasing of the current question,\n",
        "- Or a decision to end the module.\n",
        "\n",
        "### Your goals:\n",
        "1. Ask the current question naturally using `ask_patient`.\n",
        "2. Interpret the patient's response using `classify_answer`.\n",
        "3. If the response is unclear or vague, use `explain` to rephrase or clarify.\n",
        "4. If the logic requires termination, use `end_module`.\n",
        "5. Always reason about what to do next based on the MINI module instructions.\n",
        "\n",
        "Here are the MINI instructions for the current module:\n",
        "{instructions}\n",
        "\n",
        "You have access to the following tools:\n",
        "{tools}\n",
        "\n",
        "Remember: always reason step by step using **Thought**, take an **Action**, pause, then reflect on the **Observation**. Only then output your **Answer**.\n",
        "\n",
        "Begin.\n",
        "\n",
        "Interview Context:\n",
        "{input}\n",
        "\n",
        "{agent_scratchpad}\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(interview_prompt_template)\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "agent = create_react_agent(\n",
        "    llm=llm,\n",
        "    tools=tools,\n",
        "    prompt=prompt,\n",
        ")\n",
        "\n",
        "from langchain_core.agents import AgentAction, AgentFinish\n",
        "\n",
        "# Initialize state\n",
        "current_question_id = \"E1\"\n",
        "intermediate_steps = []\n",
        "agent_step = None\n",
        "question_dict = {q[\"id\"]: q for q in questions}\n",
        "\n",
        "while not isinstance(agent_step, AgentFinish):\n",
        "    # 1. Invoke the agent with input and intermediate steps\n",
        "    question_prompt = question_dict[current_question_id][\"prompt\"]\n",
        "\n",
        "    agent_step = agent.invoke({\n",
        "        \"input\": question_prompt,\n",
        "        \"intermediate_steps\": intermediate_steps,\n",
        "    })\n",
        "\n",
        "    # 2. If it's an action, run the tool manually\n",
        "    if isinstance(agent_step, AgentAction):\n",
        "        tool_name = agent_step.tool\n",
        "        tool_input = agent_step.tool_input\n",
        "\n",
        "        tool = next(t for t in tools if t.name == tool_name)\n",
        "        observation = tool.invoke(tool_input)\n",
        "\n",
        "        print(f\"\\nTool: {tool_name}\")\n",
        "        print(f\"Input: {tool_input}\")\n",
        "        print(f\"Observation: {observation}\")\n",
        "\n",
        "        # Append to scratchpad\n",
        "        intermediate_steps.append((agent_step, observation))\n",
        "\n",
        "# 3. Done — agent produced final answer\n",
        "if isinstance(agent_step, AgentFinish):\n",
        "    print(\"\\nFinal Answer:\", agent_step.return_values[\"output\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "C-E2zlKxWNSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "class Agent:\n",
        "    def __init__(self, system=\"\"):\n",
        "        self.system = system\n",
        "        self.messages = []\n",
        "        if self.system:\n",
        "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
        "\n",
        "    def __call__(self, message):\n",
        "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "        result = self.execute()\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
        "        return result\n",
        "\n",
        "    def execute(self):\n",
        "        completion = client.chat.completions.create(\n",
        "                        model=\"gpt-4o\",\n",
        "                        temperature=0,\n",
        "                        messages=self.messages)\n",
        "        return completion.choices[0].message.content\n",
        ""
      ],
      "metadata": {
        "id": "L10vC21CWOx0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}